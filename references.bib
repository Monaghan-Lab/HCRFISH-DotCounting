@article{RN153,
   author = {Bahry, Ella and Breimann, Laura and Zouinkhi, Marwan and Epstein, Leo and Kolyvanov, Klim and Mamrak, Nicholas and King, Benjamin and Long, Xi and Harrington, Kyle I. S. and Lionnet, Timothée and Preibisch, Stephan},
   title = {RS-FISH: precise, interactive, fast, and scalable FISH spot detection},
   journal = {Nature Methods},
   volume = {19},
   number = {12},
   pages = {1563-1567},
   abstract = {Fluorescent in-situ hybridization (FISH)-based methods extract spatially resolved genetic and epigenetic information from biological samples by detecting fluorescent spots in microscopy images, an often challenging task. We present Radial Symmetry-FISH (RS-FISH), an accurate, fast, and user-friendly software for spot detection in two- and three-dimensional images. RS-FISH offers interactive parameter tuning and readily scales to large datasets and image volumes of cleared or expanded samples using distributed processing on workstations, clusters, or the cloud. RS-FISH maintains high detection accuracy and low localization error across a wide range of signal-to-noise ratios, a key feature for single-molecule FISH, spatial transcriptomics, or spatial genomics applications.},
   ISSN = {1548-7105},
   DOI = {10.1038/s41592-022-01669-y},
   url = {https://doi.org/10.1038/s41592-022-01669-y},
   year = {2022},
   type = {Journal Article}
}

@article{RN149,
   author = {Choi, Harry M. T. and Schwarzkopf, Maayan and Fornace, Mark E. and Acharya, Aneesh and Artavanis, Georgios and Stegmaier, Johannes and Cunha, Alexandre and Pierce, Niles A.},
   title = {Third-generation in situ hybridization chain reaction: multiplexed, quantitative, sensitive, versatile, robust},
   journal = {Development},
   volume = {145},
   number = {12},
   pages = {dev165753},
   abstract = {In situ hybridization based on the mechanism of the hybridization chain reaction (HCR) has addressed multi-decade challenges that impeded imaging of mRNA expression in diverse organisms, offering a unique combination of multiplexing, quantitation, sensitivity, resolution and versatility. Here, with third-generation in situ HCR, we augment these capabilities using probes and amplifiers that combine to provide automatic background suppression throughout the protocol, ensuring that reagents will not generate amplified background even if they bind non-specifically within the sample. Automatic background suppression dramatically enhances performance and robustness, combining the benefits of a higher signal-to-background ratio with the convenience of using unoptimized probe sets for new targets and organisms. In situ HCR v3.0 enables three multiplexed quantitative analysis modes: (1) qHCR imaging – analog mRNA relative quantitation with subcellular resolution in the anatomical context of whole-mount vertebrate embryos; (2) qHCR flow cytometry – analog mRNA relative quantitation for high-throughput expression profiling of mammalian and bacterial cells; and (3) dHCR imaging – digital mRNA absolute quantitation via single-molecule imaging in thick autofluorescent samples.},
   ISSN = {0950-1991},
   DOI = {10.1242/dev.165753},
   url = {https://doi.org/10.1242/dev.165753},
   year = {2018},
   type = {Journal Article}
}

@article{RN152,
   author = {Pachitariu, Marius and Stringer, Carsen},
   title = {Cellpose 2.0: how to train your own model},
   journal = {Nature Methods},
   volume = {19},
   number = {12},
   pages = {1634-1641},
   abstract = {Pretrained neural network models for biological segmentation can provide good out-of-the-box results for many image types. However, such models do not allow users to adapt the segmentation style to their specific needs and can perform suboptimally for test images that are very different from the training images. Here we introduce Cellpose 2.0, a new package that includes an ensemble of diverse pretrained models as well as a human-in-the-loop pipeline for rapid prototyping of new custom models. We show that models pretrained on the Cellpose dataset can be fine-tuned with only 500–1,000 user-annotated regions of interest (ROI) to perform nearly as well as models trained on entire datasets with up to 200,000 ROI. A human-in-the-loop approach further reduced the required user annotation to 100–200 ROI, while maintaining high-quality segmentations. We provide software tools such as an annotation graphical user interface, a model zoo and a human-in-the-loop pipeline to facilitate the adoption of Cellpose 2.0.},
   ISSN = {1548-7105},
   DOI = {10.1038/s41592-022-01663-4},
   url = {https://doi.org/10.1038/s41592-022-01663-4},
   year = {2022},
   type = {Journal Article}
}

@article{RN150,
   author = {Schindelin, Johannes and Arganda-Carreras, Ignacio and Frise, Erwin and Kaynig, Verena and Longair, Mark and Pietzsch, Tobias and Preibisch, Stephan and Rueden, Curtis and Saalfeld, Stephan and Schmid, Benjamin and Tinevez, Jean-Yves and White, Daniel James and Hartenstein, Volker and Eliceiri, Kevin and Tomancak, Pavel and Cardona, Albert},
   title = {Fiji: an open-source platform for biological-image analysis},
   journal = {Nature Methods},
   volume = {9},
   number = {7},
   pages = {676-682},
   abstract = {Presented is an overview of the image-analysis software platform Fiji, a distribution of ImageJ that updates the underlying ImageJ architecture and adds modern software design elements to expand the capabilities of the platform and facilitate collaboration between biologists and computer scientists.},
   ISSN = {1548-7105},
   DOI = {10.1038/nmeth.2019},
   url = {https://doi.org/10.1038/nmeth.2019},
   year = {2012},
   type = {Journal Article}
}

@article{RN151,
   author = {Stringer, Carsen and Wang, Tim and Michaelos, Michalis and Pachitariu, Marius},
   title = {Cellpose: a generalist algorithm for cellular segmentation},
   journal = {Nature Methods},
   volume = {18},
   number = {1},
   pages = {100-106},
   abstract = {Many biological applications require the segmentation of cell bodies, membranes and nuclei from microscopy images. Deep learning has enabled great progress on this problem, but current methods are specialized for images that have large training datasets. Here we introduce a generalist, deep learning-based segmentation method called Cellpose, which can precisely segment cells from a wide range of image types and does not require model retraining or parameter adjustments. Cellpose was trained on a new dataset of highly varied images of cells, containing over 70,000 segmented objects. We also demonstrate a three-dimensional (3D) extension of Cellpose that reuses the two-dimensional (2D) model and does not require 3D-labeled data. To support community contributions to the training data, we developed software for manual labeling and for curation of the automated results. Periodically retraining the model on the community-contributed data will ensure that Cellpose improves constantly.},
   ISSN = {1548-7105},
   DOI = {10.1038/s41592-020-01018-x},
   url = {https://doi.org/10.1038/s41592-020-01018-x},
   year = {2021},
   type = {Journal Article}
}

@ARTICLE{9387490,
  author={Granger, Brian E. and Pérez, Fernando},
  journal={Computing in Science & Engineering}, 
  title={Jupyter: Thinking and Storytelling With Code and Data}, 
  year={2021},
  volume={23},
  number={2},
  pages={7-14},
  doi={10.1109/MCSE.2021.3059263}}
